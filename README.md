# HuMaIN
Work on NSF grant ACI-1535086: Human- and Machine-Intelligent Software Elements for Cost-Effective Scientific Data Digitization.<br/>
<br/>
Biodiversity information extraction (IE) from imaged text in digitized museum specimen records is a challenging task due to both the large number of labels and the complexity of the characters and information to be extracted. <br/>
The HuMaIN project investigates software-enabled solutions that support the combination of machine and human intelligence to accelerate IE from specimen labels.<br/>
Among other contributions, the project proposed the use of self-aware workflows to orchestrate machines and human tasks (the SELFIE model), Optical Character Recognition (OCR) ensembles and Natural Language Processing (NLP) methods to increase confidence in extracted text, named-entity recognition (NER) techniques for Darwin Core (DC) terms extraction, and a simulator for the study of these workflows with real-world data. The software has been tested and applied on large datasets from museums in the USA and Australia.<br/>
<br/>

## General Information Extraction and Confidence Estimation Methods (2020)
Paper: Darwin-core Terms Extraction and Confidence Estimation in Self-aware Workflows. Icaro Alzuru, Andréa Matsunaga, Maurício Tsugawa, Paul Flemons, Austin Mast, and José A.B. Fortes. To be submitted.<br/>
<br/>
This study proposes extraction and confidence estimation methods that can be applied to many DC terms in SELFIE workflows.<br/>

## HuMaIN Simulator (2019)
Paper: Human-Machine Information Extraction Simulator for Biological Collections. Icaro Alzuru, Aditi Malladi, Andréa Matsunaga, Maurício Tsugawa, and José A.B. Fortes. IEEE 3rd HMData Workshop, 2019.<br/>

## OCR Ensembles for Text Extraction (2019)
Paper: Quality-aware Human-Machine Text Extraction for Biocollections using Ensembles of OCRs. Icaro Alzuru, Rhiannon Stephens, Andréa Matsunaga, Maurício Tsugawa, Paul Flemons, and José A.B. Fortes. IEEE 15th eScience, 2019.<br/>

## Self-aware Information Extraction (SELFIE) from Biocollections (2017)
Paper: SELFIE: Self-aware Information Extraction from Digitized Biocollections. Icaro Alzuru, Andréa Matsunaga, Maurício Tsugawa, and José A.B. Fortes. IEEE 13th eScience, 2017.[doi.org/10.1109/eScience.2017.19](http://doi.org/10.1109/eScience.2017.19)<br/>

## Task Design and Crowd Sentiment in IE from Biocollections (2017)
Paper: Task Design and Crowd Sentiment in Biocollections Information Extraction. Icaro Alzuru, Andréa Matsunaga, Maurício Tsugawa, and José A.B. Fortes. 3rd IEEE Collaboration and Internet Computing, 2017. [doi.org/10.1109/CIC.2017.00056](http://doi.org/10.1109/CIC.2017.00056)<br/>

## Cooperative Human-Machine Data Extraction (2016)
*Cooperative Human-Machine Data Extraction from Biological Collections*. Icaro Alzuru, Andréa Matsunaga, Maurício Tsugawa, and José A.B. Fortes. 12th IEEE eScience, 2016. [doi.org/10.1109/eScience.2016.7870884](http://doi.org/10.1109/eScience.2016.7870884)<br/>
<br/>
This study shows how OCRopus and Tesseract, two widely used open source OCR engines, can improve their accuracy by more than 42%, when text segments are cropped by humans instead of their automated process. Our experiments also reveal differences in speed and quality between Tesseract and OCRopus.<br/>
To have access to the Python scripts utilized in the experiments, please check the [GitHib repository](https://github.com/acislab/HuMaIN_Collaborative_Data_Extraction) of the paper.