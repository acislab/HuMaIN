# HuMaIN [(humain.acis.ufl.edu)](http://humain.acis.ufl.edu/)
Work on NSF grant ACI-1535086: Human- and Machine-Intelligent Software Elements for Cost-Effective Scientific Data Digitization.<br/>
<br/>
Biodiversity information extraction (IE) from imaged text in digitized museum specimen records is a challenging task due to both the large number of labels and the complexity of the characters and information to be extracted. <br/>
The HuMaIN project investigates software-enabled solutions that support the combination of machine and human intelligence to accelerate IE from specimen labels.<br/>
Among other contributions, the project proposed the use of self-aware workflows to orchestrate machines and human tasks (the SELFIE model), Optical Character Recognition (OCR) ensembles and Natural Language Processing (NLP) methods to increase confidence in extracted text, named-entity recognition (NER) techniques for Darwin Core (DC) terms extraction, and a simulator for the study of these workflows with real-world data. The software has been tested and applied on large datasets from museums in the USA and Australia.<br/>
<br/>

## General Information Extraction and Confidence Estimation Methods
**Description**: This study proposes extraction and confidence estimation methods that can be applied to many DC terms in SELFIE workflows. A method to automatically train a named-entity recognition model is utilized for information extraction, while local and global frequency lists are utilized for confidence estimation.<br/>
**Paper**: Icaro Alzuru, Andréa Matsunaga, Maurício Tsugawa, Paul Flemons, Austin Mast, and José A.B. Fortes, *Darwin-core Terms Extraction and Confidence Estimation in Self-aware Workflows*. To be submitted.<br/>

## HuMaIN Simulator
**Description**: <br/>
**Paper**: Icaro Alzuru, Aditi Malladi, Andréa Matsunaga, Maurício Tsugawa, and José A.B. Fortes, *Human-Machine Information Extraction Simulator for Biological Collections*, 2019 IEEE International Conference on Big Data (Big Data), Los Angeles, CA, USA, 2019, pp. 4565-4572. [10.1109/BigData47090.2019.9005601](https://doi.org/10.1109/BigData47090.2019.9005601)<br/>
To have access to the scripts utilized in the experiments, please check the [repository of the paper](https://github.com/acislab/HuMaIN_Simulator).

## OCR Ensembles for Text Extraction
**Description**: <br/>
**Paper**: Icaro Alzuru, Rhiannon Stephens, Andréa Matsunaga, Maurício Tsugawa, Paul Flemons, and José A.B. Fortes, *Quality-Aware Human-Machine Text Extraction for Biocollections using Ensembles of OCRs*, 2019 15th International Conference on eScience (eScience), San Diego, CA, USA, 2019, pp. 116-125. [10.1109/eScience.2019.00020](https://doi.org/10.1109/eScience.2019.00020) <br/>
To have access to the scripts utilized in the experiments, please check the [repository  of the paper](https://github.com/acislab/HuMaIN_Text_Extraction).

## Self-aware Information Extraction (SELFIE) from Biocollections
**Description**: <br/>
**Paper**: Icaro Alzuru, Andréa Matsunaga, Maurício Tsugawa, and José A.B. Fortes, *SELFIE: Self-Aware Information Extraction from Digitized Biocollections*, 2017 IEEE 13th International Conference on e-Science (e-Science), Auckland, 2017, pp. 69-78. [doi.org/10.1109/eScience.2017.19](http://doi.org/10.1109/eScience.2017.19)<br/>
To have access to the scripts utilized in the experiments, please check the [repository  of the paper](https://github.com/acislab/HuMaIN_Self-aware_Information_Extraction).

## Task Design and Crowd Sentiment in IE from Biocollections
**Description**: <br/>
**Paper**: Icaro Alzuru, Andréa Matsunaga, Maurício Tsugawa, and José A.B. Fortes, *Task Design and Crowd Sentiment in Biocollections Information Extraction*, 2017 IEEE 3rd International Conference on Collaboration and Internet Computing (CIC), San Jose, CA, 2017, pp. 389-398. [doi.org/10.1109/CIC.2017.00056](http://doi.org/10.1109/CIC.2017.00056)<br/>
To have access to the scripts utilized in the experiments, please check the [repository  of the paper](https://github.com/acislab/HuMaIN_Crowdsourcing_Complexity).

## Cooperative Human-Machine Data Extraction
**Description**: This study shows how OCRopus and Tesseract, two widely used open-source OCR engines, can improve their accuracy by more than 42%, when text segments are cropped by humans instead of their automated process. Our experiments also reveal differences in speed and quality between Tesseract and OCRopus.<br/>
**Paper**: Icaro Alzuru, Andréa Matsunaga, Maurício Tsugawa, and José A.B. Fortes, *Cooperative human-machine data extraction from biological collections*, 2016 IEEE 12th International Conference on e-Science (e-Science), Baltimore, MD, 2016, pp. 41-50. [doi.org/10.1109/eScience.2016.7870884](http://doi.org/10.1109/eScience.2016.7870884)<br/>
To have access to the scripts utilized in the experiments, please check the [repository  of the paper](https://github.com/acislab/HuMaIN_Collaborative_Data_Extraction).